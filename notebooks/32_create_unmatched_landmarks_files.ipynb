{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T11:51:19.581962Z",
     "start_time": "2024-11-09T11:51:18.928903Z"
    }
   },
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from scripts.sample_db import SampleDB\n",
    "from skimage import measure\n",
    "import tifffile\n",
    "\n",
    "def create_bigwarp_csv_from_centroids(filename, centroids, moving=\"EM\", fixed=\"LM\"):\n",
    "    columns = ['Point_id', 'Active', 'moving_x', 'moving_y', 'moving_z', 'fixed_x', 'fixed_y', 'fixed_z']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        point_id = f\"Pt-{i}\"\n",
    "        if moving == \"EM\":\n",
    "            row = [point_id, \"false\"] + list(centroid) + [\"Infinity\", \"Infinity\", \"Infinity\"]\n",
    "        else:\n",
    "            row = [point_id, \"false\", \"Infinity\", \"Infinity\", \"Infinity\"] + list(centroid)\n",
    "        df.loc[len(df)] = row\n",
    "    df.to_csv(filename, index=False, header=None, quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "def read_landmarks_csv(file_path, chunksize=None):\n",
    "    df = pd.read_csv(file_path, header=None, \n",
    "                     names=['Point_id', 'Active', 'moving_x', 'moving_y', 'moving_z', 'fixed_x', 'fixed_y', 'fixed_z'],\n",
    "                     quoting=csv.QUOTE_ALL,\n",
    "                     dtype={'Point_id': str, 'Active': str, 'moving_x': str, 'moving_y': str, 'moving_z': str, \n",
    "                            'fixed_x': str, 'fixed_y': str, 'fixed_z': str})\n",
    "    return df\n",
    "\n",
    "def merge_landmarks(df1, df2):\n",
    "    last_point_id = df1['Point_id'].str.extract('(\\d+)').astype(int).max()\n",
    "    # Update all Point_ids by adding (last_point_id + 1)\n",
    "    df2['Point_id'] = 'Pt-' + (df2['Point_id'].str.extract('(\\d+)').astype(int) + last_point_id + 1).astype(str)\n",
    "    \n",
    "    merged_landmarks = pd.concat([df1, df2])\n",
    "    return merged_landmarks\n",
    "\n",
    "def chunk_unmatched_landmarks(file_path, chunk_size=3000):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = read_landmarks_csv(file_path)\n",
    "    # Yield chunks of DataFrame\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        yield df.iloc[i:i + chunk_size]\n",
    "        \n",
    "def switch_fix_mov_columns(df):\n",
    "    df = df[['Point_id', 'Active', 'fixed_x', 'fixed_y', 'fixed_z', 'moving_x', 'moving_y', 'moving_z']]\n",
    "    df = df.rename({'fixed_x':'moving_x', 'fixed_y':'moving_y', 'fixed_z':'moving_z', 'moving_x':'fixed_x', 'moving_y':'fixed_y', 'moving_z':'fixed_z'}, errors='raise', axis=1)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def save_landmarks_csv(df,filename):\n",
    "    df.to_csv(filename, index=False, header=False, quoting=csv.QUOTE_ALL)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T11:51:19.676971Z",
     "start_time": "2024-11-09T11:51:19.583959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the sample database\n",
    "db_path = r'\\\\tungsten-nas.fmi.ch\\tungsten\\scratch\\gfriedri\\montruth\\sample_db.csv'\n",
    "sample_db = SampleDB()\n",
    "sample_db.load(db_path)\n",
    "\n",
    "# Get the sample\n",
    "exp = sample_db.get_sample('20220511_RM0008_126hpf_fP10_f2')\n",
    "\n",
    "# Update EM paths\n",
    "em_stack_path = r'\\\\tungsten-nas.fmi.ch\\tungsten\\scratch\\gfriedri\\montruth\\CLEM_Analyses\\CLEM_20220511_RM0008_126hpf_fP10_f2\\fine_aligned_em_stack_20220511_RM0008_126hpf_fP10_f2_ds4_woResin_144nm_px_from15.tif'\n",
    "\n",
    "em_mask_path = r'\\\\tungsten-nas.fmi.ch\\tungsten\\scratch\\gfriedri\\montruth\\CLEM_Analyses\\CLEM_20220511_RM0008_126hpf_fP10_f2\\fine_aligned_em_stack_20220511_RM0008_126hpf_fP10_f2_ds4_woResin_144nm_px_from15_cp_masks_ft04_cp-3.tif'\n",
    "\n",
    "exp.em_stack_path = em_stack_path\n",
    "exp.em_mask_path = em_mask_path\n",
    "\n",
    "# Create BigWarp CSV files\n",
    "bigwarp_path = os.path.join(exp.paths.root_path, \"bigwarp_alignment\")\n",
    "os.makedirs(bigwarp_path, exist_ok=True)\n",
    "\n",
    "# Save the updated database\n",
    "print(f\"Sample database updated and saved to {db_path}\")\n",
    "\n",
    "# Define file paths of unmatched files\n",
    "unmatched_landmarks_mov_EM_fix_LM_file =  f'unmatched_landmarks_mov_EM_fix_LM_{exp.sample.id}.csv'\n",
    "unmatched_landmarks_mov_LM_fix_EM_file =  f'unmatched_landmarks_mov_LM_fix_EM_{exp.sample.id}.csv'"
   ],
   "id": "74f9ddb90ae1e0e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample database updated and saved to \\\\tungsten-nas.fmi.ch\\tungsten\\scratch\\gfriedri\\montruth\\sample_db.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Load EM mask, calculate centroids, create and chunk unmatched landmark files, create centroids LUT.",
   "id": "3afcbde69c8f18fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T14:09:06.651846Z",
     "start_time": "2024-09-11T14:06:23.432308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load EM stack\n",
    "em_mask = tifffile.imread(em_mask_path)\n",
    "em_props = measure.regionprops(em_mask)\n",
    "em_centroids = np.array([prop.centroid for prop in em_props])\n",
    "\n",
    "\n",
    "new_landmarks = em_centroids[:, ::-1]  # Flip coordinates to match coordinate sequence of BigWarp\n",
    "selected_indices = np.random.choice(len(em_centroids), len(em_centroids), replace=False)\n",
    "selected_centroids = new_landmarks[selected_indices].astype(str)\n",
    "new_landmarks_rnd = selected_centroids.tolist()\n",
    "\n",
    "\n",
    "\n",
    "create_bigwarp_csv_from_centroids(os.path.join(bigwarp_path, unmatched_landmarks_mov_LM_fix_EM_file), new_landmarks_rnd, fixed=\"LM\")\n",
    "create_bigwarp_csv_from_centroids(os.path.join(bigwarp_path, unmatched_landmarks_mov_EM_fix_LM_file), new_landmarks_rnd, fixed=\"EM\")\n",
    "\n",
    "# Create and save centroids lookup table\n",
    "centroid_list = [tuple(centroid) for centroid in em_centroids]\n",
    "centroids_lut = pd.DataFrame({\n",
    "    'id': range(1, len(centroid_list) + 1),\n",
    "    'em_centroids_zyx_px': centroid_list\n",
    "})\n",
    "centroids_lut.to_csv(os.path.join(bigwarp_path, 'lut_centroids.csv'), index=False)"
   ],
   "id": "f3f3381fd23d9b8b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T17:48:41.856412Z",
     "start_time": "2024-09-09T17:48:41.346118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create chunks of unmatched landmarks\n",
    "chunks = chunk_unmatched_landmarks(os.path.join(bigwarp_path,unmatched_landmarks_mov_EM_fix_LM_file))\n",
    "# Save each chunk as a separate CSV file\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create the new filename with the chunk number as prefix\n",
    "    filename = os.path.join(bigwarp_path, f\"chunk_{i}_{unmatched_landmarks_mov_EM_fix_LM_file}\")\n",
    "    save_landmarks_csv(chunk, filename)"
   ],
   "id": "708b1b15d4f4b6ac",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 2: Find rough landmarks with BigWarp\n",
    "* Load EM stack and LM mask (with both channels if available)\n",
    "* Explore and create rough_landmarks_mov_EM_fix_LM_20220511_sample_id.csv"
   ],
   "id": "a9991039f51609e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 3: Add unmatched landmarks to rough landmarks",
   "id": "22fed50535c26aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T11:22:21.251047Z",
     "start_time": "2024-10-23T11:22:21.077030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read rough landmarks csv file\n",
    "rough_landmarks_path = os.path.join(bigwarp_path, f'fine_landmarks_mov_LM_fix_EM_{exp.sample.id}.csv')\n",
    "rough_landmarks = read_landmarks_csv(rough_landmarks_path)\n",
    "\n",
    "mov_LM_fix_EM = \"mov_LM_fix_EM\" in rough_landmarks_path\n",
    "\n",
    "n = 6\n",
    "new_landmarks_path = os.path.join(bigwarp_path, f\"chunk_{n}_{unmatched_landmarks_mov_EM_fix_LM_file}\")\n",
    "new_landmarks = read_landmarks_csv(new_landmarks_path)\n",
    "\n",
    "if mov_LM_fix_EM:\n",
    "    new_landmarks = switch_fix_mov_columns(new_landmarks)\n",
    "    output_substring = \"fine_landmarks_mov_LM_fix_EM\"\n",
    "\n",
    "else:\n",
    "    output_substring = \"fine_landmarks_mov_EM_fix_LM\"\n",
    "\n",
    "# Create output filename with timestamp\n",
    "now = datetime.now()\n",
    "formatted_datetime = now.strftime('%Y%m%d_%H%M%S')\n",
    "output_file = os.path.join(bigwarp_path, f'{formatted_datetime}_{output_substring}_{exp.sample.id}.csv')\n",
    "\n",
    "merged_landmarks = merge_landmarks(rough_landmarks[rough_landmarks[\"Active\"] == \"true\"], new_landmarks)\n",
    "\n",
    "save_landmarks_csv(merged_landmarks,output_file)\n",
    "\n",
    "print(f\"File created at {output_file}\")"
   ],
   "id": "fc17b7f3d2dcd9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created at \\\\tungsten-nas.fmi.ch\\tungsten\\scratch\\gfriedri\\montruth\\2P_RawData\\2022-05-11\\f2\\bigwarp_alignment\\20241023_132221_fine_landmarks_mov_LM_fix_EM_20220511_RM0008_126hpf_fP10_f2.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T11:53:48.830061Z",
     "start_time": "2024-11-09T11:53:48.766058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# After fine alignment switch the mov LM to fix LM to get the warped EM stack in BigWarp\n",
    "\n",
    "# Read rough landmarks csv file\n",
    "final_landmarks_path = os.path.join(bigwarp_path, f'fine_landmarks_mov_LM_fix_EM_{exp.sample.id}.csv')\n",
    "final_landmarks = read_landmarks_csv(final_landmarks_path)\n",
    "\n",
    "mov_LM_fix_EM = \"mov_LM_fix_EM\" in final_landmarks_path\n",
    "print(mov_LM_fix_EM)\n",
    "final_landmarks_switched = switch_fix_mov_columns(final_landmarks)"
   ],
   "id": "74e4608ab144021d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T11:53:52.336334Z",
     "start_time": "2024-11-09T11:53:52.312334Z"
    }
   },
   "cell_type": "code",
   "source": "final_landmarks.head()",
   "id": "a24d9201821aac87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Point_id Active            moving_x            moving_y            moving_z  \\\n",
       "0    Pt-25   true   363.9445824866283  132.99577150983203  17.054340413748665   \n",
       "1    Pt-28   true   52.14850524427385   93.80106688473383  63.735674012180205   \n",
       "2   Pt-236   true  347.19933092508325  222.38903158760263   98.60927481831601   \n",
       "3   Pt-373   true  48.802704768749194  173.31730784300294   89.03287801175833   \n",
       "4  Pt-1804   true   427.6857016435371   90.23241740156004   60.55589273562157   \n",
       "\n",
       "              fixed_x            fixed_y             fixed_z  \n",
       "0  1133.2430547720871  601.4250768869815   468.9082320745107  \n",
       "1   396.3175622435242   567.620247498691   705.9781873709779  \n",
       "2   1046.002568618817  815.3448554234552  283.36980772053425  \n",
       "3   340.3053282226596    665.14789875341  505.25201146448427  \n",
       "4  1266.6205592731626  720.6956095968663   592.1766225994234  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point_id</th>\n",
       "      <th>Active</th>\n",
       "      <th>moving_x</th>\n",
       "      <th>moving_y</th>\n",
       "      <th>moving_z</th>\n",
       "      <th>fixed_x</th>\n",
       "      <th>fixed_y</th>\n",
       "      <th>fixed_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pt-25</td>\n",
       "      <td>true</td>\n",
       "      <td>363.9445824866283</td>\n",
       "      <td>132.99577150983203</td>\n",
       "      <td>17.054340413748665</td>\n",
       "      <td>1133.2430547720871</td>\n",
       "      <td>601.4250768869815</td>\n",
       "      <td>468.9082320745107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pt-28</td>\n",
       "      <td>true</td>\n",
       "      <td>52.14850524427385</td>\n",
       "      <td>93.80106688473383</td>\n",
       "      <td>63.735674012180205</td>\n",
       "      <td>396.3175622435242</td>\n",
       "      <td>567.620247498691</td>\n",
       "      <td>705.9781873709779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pt-236</td>\n",
       "      <td>true</td>\n",
       "      <td>347.19933092508325</td>\n",
       "      <td>222.38903158760263</td>\n",
       "      <td>98.60927481831601</td>\n",
       "      <td>1046.002568618817</td>\n",
       "      <td>815.3448554234552</td>\n",
       "      <td>283.36980772053425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pt-373</td>\n",
       "      <td>true</td>\n",
       "      <td>48.802704768749194</td>\n",
       "      <td>173.31730784300294</td>\n",
       "      <td>89.03287801175833</td>\n",
       "      <td>340.3053282226596</td>\n",
       "      <td>665.14789875341</td>\n",
       "      <td>505.25201146448427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pt-1804</td>\n",
       "      <td>true</td>\n",
       "      <td>427.6857016435371</td>\n",
       "      <td>90.23241740156004</td>\n",
       "      <td>60.55589273562157</td>\n",
       "      <td>1266.6205592731626</td>\n",
       "      <td>720.6956095968663</td>\n",
       "      <td>592.1766225994234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T11:55:35.722647Z",
     "start_time": "2024-11-09T11:55:33.457476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_landmarks_switched.head()\n",
    "final_landmarks_switched_path = os.path.join(bigwarp_path, f'fine_landmarks_mov_EM_fix_LM_{exp.sample.id}.csv')\n",
    "save_landmarks_csv(final_landmarks_switched,final_landmarks_switched_path)\n"
   ],
   "id": "65d56e465d394c8",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
